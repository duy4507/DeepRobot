{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQNvF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE78MQpnCYoZ"
      },
      "source": [
        "#@title Install necessary dependencies.\r\n",
        "\r\n",
        "!sudo apt-get install -y xvfb\r\n",
        "!pip install 'gym==0.10.11'\r\n",
        "!pip install imageio\r\n",
        "!pip install PILLOW\r\n",
        "!pip install 'pyglet==1.3.2'\r\n",
        "!pip install pyvirtualdisplay\r\n",
        "\r\n",
        "!pip install dm-acme\r\n",
        "!pip install dm-acme[reverb]\r\n",
        "!pip install dm-acme[tf]\r\n",
        "!pip install dm-acme[envs]\r\n",
        "!pip install -q tf-agents\r\n",
        "\r\n",
        "from IPython.display import clear_output\r\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmbR3y2WCa1C"
      },
      "source": [
        "#@title Importer les modules.\r\n",
        "#python3\r\n",
        "\r\n",
        "%%capture\r\n",
        "import copy\r\n",
        "import pyvirtualdisplay\r\n",
        "import imageio \r\n",
        "import base64\r\n",
        "import IPython\r\n",
        "\r\n",
        "\r\n",
        "from acme import environment_loop\r\n",
        "from acme.tf import networks\r\n",
        "from acme.adders import reverb as adders\r\n",
        "from acme.agents.tf import actors as actors\r\n",
        "from acme.datasets import reverb as datasets\r\n",
        "from acme.wrappers import gym_wrapper\r\n",
        "from acme import specs\r\n",
        "from acme import wrappers\r\n",
        "from acme.agents.tf import dqn\r\n",
        "from acme.agents import agent\r\n",
        "from acme.tf import utils as tf2_utils\r\n",
        "from acme.utils import loggers\r\n",
        "from tf_agents.networks import q_network\r\n",
        "from tf_agents.environments import tf_py_environment\r\n",
        "from tf_agents.environments import suite_gym\r\n",
        "\r\n",
        "\r\n",
        "import gym \r\n",
        "import dm_env\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import reverb\r\n",
        "import sonnet as snt\r\n",
        "import tensorflow as tf\r\n",
        "import trfl\r\n",
        "import torch\r\n",
        "\r\n",
        "\r\n",
        "# Render une video pour l'environnment.\r\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1920, 1080)).start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDF9BfRZCgAD",
        "outputId": "c1293759-9f92-4a18-c4e3-4c77f6e4baf0"
      },
      "source": [
        "#@title Choisir l'environnement\r\n",
        "environment_name = 'gym_mountaincar'\r\n",
        "\r\n",
        "def make_environment(domain_name='cartpole', task='balance'):\r\n",
        "  env = suite.load(domain_name, task)\r\n",
        "  env = wrappers.SinglePrecisionWrapper(env)\r\n",
        "  return env\r\n",
        "\r\n",
        "if 'gym_mountaincar' in environment_name:\r\n",
        "  environment = gym_wrapper.GymWrapper(gym.make('MountainCarContinuous-v0'))\r\n",
        "  environment = wrappers.SinglePrecisionWrapper(environment)\r\n",
        "  def render(env):\r\n",
        "    return env.environment.render(mode='rgb_array')\r\n",
        "else:\r\n",
        "  raise ValueError('Unknown environment: {}.'.format(environment_name))\r\n",
        "\r\n",
        "# Show the frame.\r\n",
        "frame = render(environment)\r\n",
        "plt.imshow(frame)\r\n",
        "plt.axis('off')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 599.5, 399.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WakmtxSkCmm2",
        "outputId": "250169ed-d653-4900-df55-8783151bc6b9"
      },
      "source": [
        "environment_spec = specs.make_environment_spec(environment)\r\n",
        "\r\n",
        "print('actions:\\n', environment_spec.actions, '\\n')\r\n",
        "print('observations:\\n', environment_spec.observations, '\\n')\r\n",
        "print('rewards:\\n', environment_spec.rewards, '\\n')\r\n",
        "print('discounts:\\n', environment_spec.discounts, '\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actions:\n",
            " BoundedArray(shape=(1,), dtype=dtype('float32'), name='action', minimum=[-1.], maximum=[1.]) \n",
            "\n",
            "observations:\n",
            " BoundedArray(shape=(2,), dtype=dtype('float32'), name='observation', minimum=[-1.2  -0.07], maximum=[0.6  0.07]) \n",
            "\n",
            "rewards:\n",
            " Array(shape=(), dtype=dtype('float32'), name='reward') \n",
            "\n",
            "discounts:\n",
            " BoundedArray(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGI-9q4DXBp_"
      },
      "source": [
        "#@title Choisir hyperparamètres\r\n",
        "epsilon = 0.5\r\n",
        "batch_size=256\r\n",
        "prefetch_size=4\r\n",
        "priority_exponent=0.6\r\n",
        "max_replay_size=1000000"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl540Kj1Xm0F"
      },
      "source": [
        "#@title Définir la fonction display_video\r\n",
        "def display_video(frames, filename='temp.mp4'):\r\n",
        "  \"\"\"Save and display video.\"\"\"\r\n",
        "  # Write video\r\n",
        "  with imageio.get_writer(filename, fps=60) as video:\r\n",
        "    for frame in frames:\r\n",
        "      video.append_data(frame)\r\n",
        "  # Read video and display the video\r\n",
        "  video = open(filename, 'rb').read()\r\n",
        "  b64_video = base64.b64encode(video)\r\n",
        "  video_tag = ('<video  width=\"320\" height=\"240\" controls alt=\"test\" '\r\n",
        "               'src=\"data:video/mp4;base64,{0}\">').format(b64_video.decode())\r\n",
        "  return IPython.display.HTML(video_tag)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSoIB6dJXpWA"
      },
      "source": [
        "timestep = environment.reset()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMdCbYVXghp9"
      },
      "source": [
        "#@title Définition du Q-Network\r\n",
        "train_py_env = suite_gym.load('MountainCarContinuous-v0')\r\n",
        "eval_py_env = suite_gym.load('MountainCarContinuous-v0')\r\n",
        "\r\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\r\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\r\n",
        "\r\n",
        "fc_layer_params = (100,)\r\n",
        "\r\n",
        "network = q_network.QNetwork(\r\n",
        "    train_env.observation_spec(),\r\n",
        "    train_env.action_spec(),\r\n",
        "    fc_layer_params=fc_layer_params)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdG7pJr3jfcU"
      },
      "source": [
        "replay_table = reverb.Table(name=adders.DEFAULT_PRIORITY_TABLE,\r\n",
        "        sampler=reverb.selectors.Prioritized(priority_exponent),\r\n",
        "        remover=reverb.selectors.Fifo(),\r\n",
        "        max_size=max_replay_size,\r\n",
        "        rate_limiter=reverb.rate_limiters.MinSize(1),\r\n",
        "        signature=adders.NStepTransitionAdder.signature(environment_spec))\r\n",
        "replay_server = reverb.Server([replay_table], port=None)\r\n",
        "replay_server_address = 'localhost:%d' % replay_server.port"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHmaonlrjlqC"
      },
      "source": [
        "#@title Adder\r\n",
        "# Create a 5-step transition adder where in between those steps a discount of\r\n",
        "# 0.99 is used (which should be the same discount used for learning).\r\n",
        "adder = adders.NStepTransitionAdder(\r\n",
        "    client=reverb.Client(replay_server_address),\r\n",
        "    n_step=5,\r\n",
        "    discount=0.99)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWfqoZKpWB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab645ecc-944f-451a-be88-68ea6b7d7f58"
      },
      "source": [
        "#@title Dataset\r\n",
        "replay_client = reverb.TFClient(replay_server_address)\r\n",
        "dataset = datasets.make_reverb_dataset(\r\n",
        "        server_address=replay_server_address,\r\n",
        "        batch_size=batch_size,\r\n",
        "        prefetch_size=prefetch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <function _yield_value at 0x7f5c4406d158> appears to be a generator function. It will not be converted by AutoGraph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dCpp1cLjzG4"
      },
      "source": [
        "#@title Policy Network\r\n",
        "num_dimensions = np.prod(environment_spec.actions.shape, dtype=int)\r\n",
        "policy_network = snt.Sequential([\r\n",
        "    networks.LayerNormMLP((256, 256, 256), activate_final=True),\r\n",
        "    networks.NearZeroInitializedLinear(num_dimensions),\r\n",
        "    networks.TanhToSpec(environment_spec.actions),\r\n",
        "  ])\r\n",
        "#policy_network = snt.Sequential([\r\n",
        " #         network,\r\n",
        "  #        lambda q: trfl.epsilon_greedy(q, epsilon=epsilon).sample(),\r\n",
        "   #   ])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWWqYiiQj9RD"
      },
      "source": [
        "#@title Target network.\r\n",
        "target_network = copy.deepcopy(network)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egwZGGJkCZs",
        "outputId": "fb3613e4-ea31-4e49-bd9e-ec4a1b6128b9"
      },
      "source": [
        "# Ensure that we create the variables before proceeding (maybe not needed).\r\n",
        "tf2_utils.create_variables(network=network, input_spec=[environment_spec.observations])\r\n",
        "tf2_utils.create_variables(network=target_network,input_spec= [environment_spec.observations])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(3,), dtype=tf.float32, name=None), ())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgHq4EfsqMXD"
      },
      "source": [
        "#@title Actor\r\n",
        "actor = actors.FeedForwardActor(policy_network=policy_network, adder=adder,)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf-z6JVf2mM4"
      },
      "source": [
        "from typing import Dict, List\r\n",
        "@tf.function\r\n",
        "def my_step(self) -> Dict[str, tf.Tensor]:\r\n",
        "  \"\"\"Do a step of SGD and update the priorities.\"\"\"\r\n",
        "\r\n",
        "  # Pull out the data needed for updates/priorities.\r\n",
        "  inputs = next(self._iterator)\r\n",
        "  o_tm1, a_tm1, r_t, d_t, o_t = inputs.data\r\n",
        "  keys, probs = inputs.info[:2]\r\n",
        "\r\n",
        "  #new instruction\r\n",
        "  print(inputs.data)\r\n",
        "  #print(o_tm1[0, 0])\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    # Evaluate our networks.\r\n",
        "    q_tm1 = self._network(o_tm1)\r\n",
        "    q_t_value = self._target_network(o_t)\r\n",
        "    q_t_selector = self._network(o_t)\r\n",
        "\r\n",
        "    print(q_tm1)\r\n",
        "    #print(q_tm1[0])\r\n",
        "    q_tm1=q_tm1[0]\r\n",
        "\r\n",
        "    print(r_t.dtype)\r\n",
        "    #print(q_tm1.dtype)\r\n",
        "\r\n",
        "    # The rewards and discounts have to have the same type as network values.\r\n",
        "    r_t = tf.cast(r_t, q_tm1.dtype.as_numpy_dtype)\r\n",
        "    r_t = tf.clip_by_value(r_t, -1., 1.)\r\n",
        "    d_t = tf.cast(d_t, q_tm1.dtype) * tf.cast(self._discount, q_tm1.dtype)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    # Compute the loss.\r\n",
        "    _, extra = trfl.double_qlearning(q_tm1, a_tm1, r_t, d_t, q_t_value,\r\n",
        "                                       q_t_selector)\r\n",
        "    loss = losses.huber(extra.td_error, self._huber_loss_parameter)\r\n",
        "\r\n",
        "    # Get the importance weights.\r\n",
        "    importance_weights = 1. / probs  # [B]\r\n",
        "    importance_weights **= self._importance_sampling_exponent\r\n",
        "    importance_weights /= tf.reduce_max(importance_weights)\r\n",
        "\r\n",
        "    # Reweight.\r\n",
        "    loss *= tf.cast(importance_weights, loss.dtype)  # [B]\r\n",
        "    loss = tf.reduce_mean(loss, axis=[0])  # []\r\n",
        "\r\n",
        "  # Do a step of SGD.\r\n",
        "  gradients = tape.gradient(loss, self._network.trainable_variables)\r\n",
        "  self._optimizer.apply(gradients, self._network.trainable_variables)\r\n",
        "\r\n",
        "  # Update the priorities in the replay buffer.\r\n",
        "  if self._replay_client:\r\n",
        "    priorities = tf.cast(tf.abs(extra.td_error), tf.float64)\r\n",
        "    self._replay_client.update_priorities(\r\n",
        "          table=adders.DEFAULT_PRIORITY_TABLE, keys=keys, priorities=priorities)\r\n",
        "\r\n",
        "  # Periodically update the target network.\r\n",
        "  if tf.math.mod(self._num_steps, self._target_update_period) == 0:\r\n",
        "    for src, dest in zip(self._network.variables,\r\n",
        "                           self._target_network.variables):\r\n",
        "        dest.assign(src)\r\n",
        "  self._num_steps.assign_add(1)\r\n",
        "\r\n",
        "  # Report loss & statistics for logging.\r\n",
        "  fetches = {\r\n",
        "        'loss': loss,\r\n",
        "    }\r\n",
        "\r\n",
        "  return fetches\r\n",
        "\r\n",
        "dqn.DQNLearner._step = my_step"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGfF6zJTkGtW"
      },
      "source": [
        "learner=dqn.DQNLearner(network=network, target_network=target_network,discount=0.99, importance_sampling_exponent=1e-3,learning_rate=0.2,target_update_period=100, dataset=dataset)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyiAesjelLju"
      },
      "source": [
        "dqn_agent = agent.Agent(actor=actor,\r\n",
        "                         learner=learner,\r\n",
        "                         min_observations=1000,\r\n",
        "                         observations_per_step=8.)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_63i0a-lPim"
      },
      "source": [
        "# This may be necessary if any of the episodes were cancelled above.\r\n",
        "adder.reset()\r\n",
        "\r\n",
        "# We also want to make sure the logger doesn't write to disk because that can\r\n",
        "# cause issues in colab on occasion.\r\n",
        "logger = loggers.TerminalLogger(time_delta=10.)\r\n",
        "agent_logger = loggers.TerminalLogger(label='agent', time_delta=10.)\r\n",
        "env_loop_logger = loggers.TerminalLogger(label='env_loop', time_delta=10.)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VMlUqr8lSDf",
        "outputId": "56ddc0d5-b174-4e55-b4e2-34dce58d7611"
      },
      "source": [
        "[method_or_attr for method_or_attr in dir(learner)  # pylint: disable=expression-not-assigned\r\n",
        " if not method_or_attr.startswith('_')]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['get_variables', 'run', 'state', 'step']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur6R2ihFlSEP"
      },
      "source": [
        "env_loop = environment_loop.EnvironmentLoop(environment=environment,actor=dqn_agent,logger=env_loop_logger)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "IuCc7bk7lW9e",
        "outputId": "b9d2cfb8-064b-4a29-ba73-16074df1e4d9"
      },
      "source": [
        "env_loop.run(50)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor 'IteratorGetNext:4' shape=(256, 2) dtype=float32>, <tf.Tensor 'IteratorGetNext:5' shape=(256, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(256,) dtype=float32>, <tf.Tensor 'IteratorGetNext:7' shape=(256,) dtype=float32>, <tf.Tensor 'IteratorGetNext:8' shape=(256, 2) dtype=float32>)\n",
            "(<tf.Tensor 'QNetwork/dense_1/BiasAdd:0' shape=(256, 3) dtype=float32>, ())\n",
            "<dtype: 'float32'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a7869d6ec55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/acme/environment_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, num_episodes, num_steps)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mepisode_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshould_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m       \u001b[0mepisode_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mstep_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/acme/environment_loop.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_timestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_update\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;31m# Book-keeping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/acme/agents/agent.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;31m# Run learner steps (usually means gradient steps).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;31m# Update the actor weights when learner updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/acme/agents/tf/dqn/learning.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Do a batch of SGD.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Compute elapsed time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3734\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-24-b96ddd638fd2>:37 my_step  *\n        _, extra = trfl.double_qlearning(q_tm1, a_tm1, r_t, d_t, q_t_value,\n    /usr/local/lib/python3.6/dist-packages/trfl/action_value_ops.py:120 double_qlearning  *\n        base_ops.wrap_rank_shape_assert(\n    /usr/local/lib/python3.6/dist-packages/trfl/base_ops.py:91 wrap_rank_shape_assert  *\n        assert_rank_and_shape_compatibility(tensors, rank)\n    /usr/local/lib/python3.6/dist-packages/trfl/base_ops.py:83 assert_rank_and_shape_compatibility  *\n        tensor_shape = tf.TensorShape(tensor.shape)\n\n    AttributeError: 'tuple' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy_ShrOrAW5b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}